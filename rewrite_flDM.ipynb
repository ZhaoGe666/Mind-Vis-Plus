{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本module包含所有fLDM的子类module  \n",
    "每个nn.Module都应该为原来nn.Module的子类,  \n",
    "Norm(本例中只含nn.LayerNorm和nn.GroupNorm,以及一个自定的GroupNorm32)的父亲(即直接或间接调用了Norm模块的)节点必须重写  \n",
    "- 直接调用的需要在init里初始化PDNorm类(替换Norm),并在forward里增加prompt到输入输出,training_step也需要修改,包括以上方法(__init__,forward,training_step)调用的方法。  \n",
    "- 间接调用的除了不需要初始化, 其余一样  \n",
    "- 不调用的就不用改了,可以用脚本(Norm not in module.named_children)快速找出  \n",
    "\n",
    "最外层两种思路:  \n",
    "- 重写fLDM  \n",
    "- 重写LatentDiffuion,将generative_model.model 载入为 new_model,而generative_model的实例变量似乎都是为了初始化LatentDiffusion载入的一些config,因此直接load_state_dict没问题  \n",
    "    \n",
    "重写后,外部先载入老模型?再初始化一个新的LatentDiffusion对象直接load_state_dict  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "init并载入一个原始模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "from dc_ldm.ldm_for_fmri import fLDM\n",
    "from config import Config_Generative_Model\n",
    "from dataset import create_Kamitani_dataset, create_BOLD5000_dataset\n",
    "\n",
    "\n",
    "\n",
    "class random_crop:\n",
    "    def __init__(self, size, p):\n",
    "        self.size = size\n",
    "        self.p = p\n",
    "    def __call__(self, img):\n",
    "        if torch.rand(1) < self.p:\n",
    "            return transforms.RandomCrop(size=(self.size, self.size))(img)\n",
    "        return img\n",
    "\n",
    "\n",
    "def normalize(img):\n",
    "    if img.shape[-1] == 3:\n",
    "        img = rearrange(img, 'h w c -> c h w')\n",
    "    img = torch.tensor(img)\n",
    "    img = img * 2.0 - 1.0 # to -1 ~ 1\n",
    "    return img\n",
    "\n",
    "def channel_last(img):\n",
    "        if img.shape[-1] == 3:\n",
    "            return img\n",
    "        return rearrange(img, 'c h w -> h w c')\n",
    "\n",
    "def fmri_transform(x, sparse_rate=0.2):\n",
    "    # x: 1, num_voxels\n",
    "    x_aug = copy.deepcopy(x)\n",
    "    idx = np.random.choice(x.shape[0], int(x.shape[0]*sparse_rate), replace=False)\n",
    "    x_aug[idx] = 0\n",
    "    return torch.FloatTensor(x_aug)\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "config = Config_Generative_Model()\n",
    "config.checkpoint_path = './results/generation/07-09-2023-01-50-29/checkpoint_best.pth'\n",
    "if config.checkpoint_path is not None:\n",
    "    model_meta = torch.load(config.checkpoint_path, map_location='cpu')\n",
    "    ckp = config.checkpoint_path\n",
    "    config = model_meta['config']\n",
    "    config.checkpoint_path = ckp  # 更新config中ckp为读取的ckp\n",
    "    print('Resuming from checkpoint: {}'.format(config.checkpoint_path))\n",
    "\n",
    "config.logger = None # FIXME:???\n",
    "pretrain_mbm_metafile = torch.load(config.pretrain_mbm_path, map_location='cpu')\n",
    "crop_pix = int(config.crop_ratio*config.img_size)\n",
    "\n",
    "img_transform_train = transforms.Compose([\n",
    "        normalize,\n",
    "        random_crop(config.img_size-crop_pix, p=0.5),\n",
    "        transforms.Resize((256, 256)), \n",
    "        channel_last\n",
    "    ])\n",
    "img_transform_test = transforms.Compose([\n",
    "        normalize, transforms.Resize((256, 256)), \n",
    "        channel_last\n",
    "    ])\n",
    "\n",
    "if config.dataset == 'GOD':\n",
    "    fmri_latents_dataset_train, fmri_latents_dataset_test = create_Kamitani_dataset(config.kam_path, config.roi, config.patch_size, \n",
    "            fmri_transform=fmri_transform, image_transform=[img_transform_train, img_transform_test], \n",
    "            subjects=config.kam_subs)\n",
    "    num_voxels = fmri_latents_dataset_train.num_voxels\n",
    "elif config.dataset == 'BOLD5000':\n",
    "    fmri_latents_dataset_train, fmri_latents_dataset_test = create_BOLD5000_dataset(config.bold5000_path, config.patch_size, \n",
    "            fmri_transform=fmri_transform, image_transform=[img_transform_train, img_transform_test], \n",
    "            subjects=config.bold5000_subs)\n",
    "    num_voxels = fmri_latents_dataset_train.num_voxels\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "generative_model = fLDM(pretrain_mbm_metafile, num_voxels,\n",
    "                device=device, pretrain_root=config.pretrain_gm_path, logger=config.logger, \n",
    "                ddim_steps=config.ddim_steps, global_pool=config.global_pool, use_time_cond=config.use_time_cond)\n",
    "\n",
    "\n",
    "def count_trainable_parameters(model):\n",
    "    for name, module in model.named_children():\n",
    "        trainable_params = sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
    "        non_trainable_params = sum(p.numel() for p in module.parameters() if not p.requires_grad)\n",
    "        print(f\"Module: {name}\")\n",
    "        print(f\"  Trainable parameters: {trainable_params/(1024*1024):.1f}M\")\n",
    "        print(f\"  Non-trainable parameters: {non_trainable_params/(1024*1024):.1f}M\")\n",
    "        print('-' * 40)\n",
    "\n",
    "# count_trainable_parameters(generative_model.model)\n",
    "stageC_model = copy.deepcopy(generative_model.model)\n",
    "if config.checkpoint_path is not None:  # 从自己fintune的checkpoint载入state\n",
    "        model_meta = torch.load(config.checkpoint_path, map_location='cpu')\n",
    "        stageC_model.load_state_dict(model_meta['model_state_dict'])\n",
    "        print('model resumed')\n",
    "count_trainable_parameters(stageC_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "冻结first_stage_model后，查看参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stageC_model.freeze_first_stage()\n",
    "count_trainable_parameters(stageC_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新建一个自定义的LDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "统计不同Norm类的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_norm(model):\n",
    "    norm_counts = {}\n",
    "    for name, module in model.named_modules():\n",
    "        class_name = module.__class__.__name__\n",
    "        # print(class_name)\n",
    "        if 'Norm' in class_name:\n",
    "            norm_counts[class_name] = norm_counts.get(class_name, 0) + 1\n",
    "            # print(module)   \n",
    "    print(norm_counts)\n",
    "\n",
    "def count_norm_i(model):\n",
    "    norm_counts = {}\n",
    "    for name, module in model.named_modules():\n",
    "        class_name = module.__class__.__name__\n",
    "        # print(class_name)\n",
    "        if 'Norm' in class_name:\n",
    "            norm_counts[class_name] = norm_counts.get(class_name, 0) + 1\n",
    "            # print(module)   \n",
    "    print(norm_counts)\n",
    "count_norm(stageC_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照树的结构打印各个module中Norm类的数量，作为重写各module的对照"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, class_name, instance_name):\n",
    "        self.class_name = class_name\n",
    "        self.instance_name = instance_name\n",
    "        self.children = defaultdict(Node)\n",
    "        self.norm_count = 0\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        return self.children[key]\n",
    "\n",
    "    def display(self, indent=0):\n",
    "        prefix = '  ' * indent\n",
    "        if self.norm_count > 0:\n",
    "            print(f\"{prefix}({self.instance_name}){self.class_name}: {self.norm_count}\")\n",
    "        for child in self.children.values():\n",
    "            child.display(indent + 1)\n",
    "\n",
    "def build_tree(module, path=[]):\n",
    "    abs_instance_name = '.'.join(path)\n",
    "    instance_name = path[-1]\n",
    "    node = Node(module.__class__.__name__, instance_name)  # 将\"类名\"传入初始化1个Node\n",
    "    # children为空，norm_count = 0\n",
    "    for child_instance_name, submodule in module.named_children():  # 遍历子模块进行递归调用\n",
    "        # abs_instance_name = '.'.join(path)\n",
    "        child_node = build_tree(submodule, path + [child_instance_name])  # 将子模块的name (instanc) 存到path中，按照类名建立子节点\n",
    "        # path 记录了子模块的变量名\n",
    "        # node.children[child_node.class_name] = child_node  \n",
    "        # # 以子节点类名为key(会导致同名类后来替代的问题)，子节点Node实例为value存入实例变量children字典中\n",
    "        node.children[child_node.instance_name] = child_node \n",
    "        # 按照instance建立树则不会重复，display时在括号中显示class_name即可\n",
    "\n",
    "        if 'Norm' in submodule.__class__.__name__:\n",
    "            child_node.norm_count += 1\n",
    "\n",
    "        node.norm_count += child_node.norm_count\n",
    "\n",
    "    return node\n",
    "\n",
    "root = build_tree(generative_model.model,['ldm_model'])\n",
    "root.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "修改LatentDiffusion，包括：  \n",
    "**属性**：  \n",
    "- self.model\n",
    "- self.first_stage_model\n",
    "- self.cond_stage_model\n",
    "\n",
    "\n",
    "**方法**： \n",
    "- training_step (DDPM,直接在LatentDiffusion中重写即可)\n",
    "    - shared_step (LatentDiffusion)\n",
    "        - get_input (LatentDiffusion)\n",
    "        - forward (LatentDiffusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdnorm_model import PDfLDM\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "config = OmegaConf.load('stageC_config.yaml')\n",
    "pd_model = PDfLDM(**config.model.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改DiffusionWrapper及其子模块，一个instance共包含了109个Norm (instance)  \n",
    "自下而上重写  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_trainable_parameters(pd_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_norm(pd_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd_model.cond_stage_model.mae.pos_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,u = pd_model.load_state_dict(stageC_model.state_dict(),strict=False)\n",
    "print('missing keys:',m)\n",
    "print('-'*40)\n",
    "print('unexpected keys:',u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for missing_key in m:\n",
    "    if 'mlp_' not in missing_key:\n",
    "        print(missing_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_model2 = PDfLDM(**config.model.params)\n",
    "mm,uu = pd_model2.load_state_dict(model_meta['model_state_dict'],strict=False)\n",
    "print('missing keys:',mm)\n",
    "print('-'*40)\n",
    "print('unexpected keys:',uu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_trainable_parameters(pd_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for missing_key in mm:\n",
    "    if 'mlp_' not in missing_key:\n",
    "        print(missing_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdnorm_model import PDNorm\n",
    "def findout_norm(model):\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, PDNorm):\n",
    "            print(name, module)\n",
    "        else:\n",
    "            findout_norm(module)\n",
    "findout_norm(pd_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(pd_model.cond_stage_model.mae.blocks[22].norm2.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 2, 'c': 3}\n"
     ]
    }
   ],
   "source": [
    "a = ['a','b','c']\n",
    "b = [1,2,3]\n",
    "c = {k:v for k,v in zip(a,b)}\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val/a': 1, 'val/b': 2, 'val/c': 3}\n"
     ]
    }
   ],
   "source": [
    "d = {f'val/{k}':v for k,v in c.items()}\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👀\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "checkpoint_path = '/data/xiaozhaoliu/stageC1/mind-vis/bjcgbjql/checkpoints/epoch=294-step=23600.ckpt'\n",
    "model_meta = torch.load(checkpoint_path, map_location='cpu')\n",
    "print('👀')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: 1.02 mins\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time_generating = time.time()\n",
    "time.sleep(61)\n",
    "end_time_generating = time.time()\n",
    "print(f\"Execution Time: {(end_time_generating - start_time_generating)/60:.2f} mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48]\n"
     ]
    }
   ],
   "source": [
    "grouped_fmri = [i for i in range(0, 50, 3)]\n",
    "print(grouped_fmri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9219)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure\n",
    "preds = torch.rand([3, 3, 256, 256])\n",
    "target = preds * 0.75\n",
    "ssim = StructuralSimilarityIndexMeasure(data_range=1.0)\n",
    "ssim(preds, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = preds[1:,:,:,:]\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7572, 0.0961, 0.7131],\n",
      "        [0.4517, 0.5330, 0.5896],\n",
      "        [0.5377, 0.6059, 0.1126]])\n",
      "tensor([[193,  24, 181],\n",
      "        [115, 135, 150],\n",
      "        [137, 154,  28]], dtype=torch.uint8)\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand([3, 3])\n",
    "print(x)\n",
    "y = (x*255).to(torch.uint8)\n",
    "print(y)\n",
    "z = y/255.\n",
    "print(z.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈\n"
     ]
    }
   ],
   "source": [
    "print('\\U0001F4C8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "<class 'numpy.ndarray'>\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from einops import rearrange, repeat\n",
    "x = torch.rand([2, 3]).to(torch.device('cuda:0')).detach()\n",
    "print(x.device)\n",
    "y = rearrange(x, 'h w -> w h').cpu().numpy()\n",
    "print(type(y))\n",
    "print(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.uint8\n",
      "cuda:0\n",
      "torch.float32\n",
      "torch.uint8\n"
     ]
    }
   ],
   "source": [
    "grouped_images = torch.randint(0,255,(5,6,3,64,64)).to(torch.uint8).to(torch.device('cuda:0'))\n",
    "print(grouped_images.dtype)\n",
    "print(grouped_images.device)\n",
    "\n",
    "all_imgs = grouped_images/255.\n",
    "print(all_imgs.dtype)\n",
    "print(grouped_images.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "from PIL import Image\n",
    "images = rearrange(grouped_images, 'b n c h w -> (b n) c h w')\n",
    "grid = make_grid(images, nrow=grouped_images.shape[2])\n",
    "grid_rgb = rearrange(grid, 'c h w -> h w c')\n",
    "grid_PIL= Image.fromarray(grid_rgb.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recon_epoch_0001\n"
     ]
    }
   ],
   "source": [
    "ep=1\n",
    "print(f'recon_epoch_{ep:04}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-11-13-11-36-26\n",
      "231113-113626\n"
     ]
    }
   ],
   "source": [
    "from pytz import timezone\n",
    "from datetime import datetime\n",
    "print(datetime.utcnow().astimezone(timezone('Asia/Shanghai')).strftime(\"%y-%m-%d-%H-%M-%S\"))\n",
    "print(datetime.utcnow().astimezone(timezone('Asia/Shanghai')).strftime(\"%y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "23-11-13-11-37-24\n",
      "23-11-13-11-37-24/checkpoint\n"
     ]
    }
   ],
   "source": [
    "run_dir = datetime.utcnow().astimezone(timezone('Asia/Shanghai')).strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "print(type(run_dir))\n",
    "print(run_dir)\n",
    "ckpt_save_dir = run_dir + '/checkpoint'\n",
    "print(ckpt_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72c07df23ed64e6ca2c195774b3b8951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from rich.progress import track\n",
    "\n",
    "for i in track(range(20), description=\"Processing...\"):\n",
    "    time.sleep(0.1)  # Simulate work being done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bold][red]Done!\n"
     ]
    }
   ],
   "source": [
    "print(f'[bold][red]Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">           Todo List           </span>\n",
       "┏━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> S. No. </span>┃<span style=\"font-weight: bold\"> Task      </span>┃<span style=\"font-weight: bold\"> Status </span>┃\n",
       "┡━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> 1      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Buy Milk  </span>│<span style=\"color: #008000; text-decoration-color: #008000\">     ✅ </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> 2      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Buy Bread </span>│<span style=\"color: #008000; text-decoration-color: #008000\">     ✅ </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> 3      </span>│<span style=\"color: #800080; text-decoration-color: #800080\"> Buy Jam   </span>│<span style=\"color: #008000; text-decoration-color: #008000\">     ❌ </span>│\n",
       "└────────┴───────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m           Todo List           \u001b[0m\n",
       "┏━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mS. No.\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mTask     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mStatus\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m1     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mBuy Milk \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m    ✅\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m2     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mBuy Bread\u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m    ✅\u001b[0m\u001b[32m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m3     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mBuy Jam  \u001b[0m\u001b[35m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m    ❌\u001b[0m\u001b[32m \u001b[0m│\n",
       "└────────┴───────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "\n",
    "table = Table(title=\"Todo List\")\n",
    "\n",
    "table.add_column(\"S. No.\", style=\"cyan\", no_wrap=True)\n",
    "table.add_column(\"Task\", style=\"magenta\")\n",
    "table.add_column(\"Status\", justify=\"right\", style=\"green\")\n",
    "\n",
    "table.add_row(\"1\", \"Buy Milk\", \"✅\")\n",
    "table.add_row(\"2\", \"Buy Bread\", \"✅\")\n",
    "table.add_row(\"3\", \"Buy Jam\", \"❌\")\n",
    "\n",
    "console = Console()\n",
    "console.print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The zipped result is : {('Nikhil', 1, 50), ('Manjeet', 4, 40), ('Shambhavi', 3, 60), ('Astha', 2, 70)}\n"
     ]
    }
   ],
   "source": [
    "# initializing lists \n",
    "name = [ \"Manjeet\", \"Nikhil\", \"Shambhavi\", \"Astha\" ] \n",
    "roll_no = [ 4, 1, 3, 2 ] \n",
    "marks = [ 40, 50, 60, 70 ] \n",
    "  \n",
    "# using zip() to map values \n",
    "mapped = zip(name, roll_no, marks) \n",
    "  \n",
    "# converting values to print as set \n",
    "mapped = set(mapped) \n",
    "  \n",
    "# printing resultant values  \n",
    "print (\"The zipped result is : \",end=\"\") \n",
    "print (mapped) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      " tensor([0, 1, 2, 3, 4])\n",
      "aa\n",
      ": tensor([[0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4]])\n",
      "b:\n",
      " tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4])\n",
      "c:\n",
      " tensor([10, 11, 12, 13, 14, 10, 11, 12, 13, 14, 10, 11, 12, 13, 14])\n",
      "d:\n",
      " tensor([[10, 11, 12, 13, 14],\n",
      "        [10, 11, 12, 13, 14],\n",
      "        [10, 11, 12, 13, 14]])\n"
     ]
    }
   ],
   "source": [
    "from einops import rearrange,repeat\n",
    "import torch\n",
    "\n",
    "a = torch.arange(0,5)\n",
    "print('a:\\n',a)\n",
    "aa = repeat(a, 'b -> n b', n=3)\n",
    "print('aa\\n:',aa)\n",
    "b = repeat(a, 'b -> (n b)', n=3)\n",
    "print('b:\\n',b)\n",
    "\n",
    "c = b+10\n",
    "print('c:\\n',c)\n",
    "d = rearrange(c,'(n b) -> n b',n=3,b=5)\n",
    "print('d:\\n',d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mind-vis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
