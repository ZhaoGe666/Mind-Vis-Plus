{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æœ¬moduleåŒ…å«æ‰€æœ‰fLDMçš„å­ç±»module  \n",
    "æ¯ä¸ªnn.Moduleéƒ½åº”è¯¥ä¸ºåŸæ¥nn.Moduleçš„å­ç±»,  \n",
    "Norm(æœ¬ä¾‹ä¸­åªå«nn.LayerNormå’Œnn.GroupNorm,ä»¥åŠä¸€ä¸ªè‡ªå®šçš„GroupNorm32)çš„çˆ¶äº²(å³ç›´æ¥æˆ–é—´æ¥è°ƒç”¨äº†Normæ¨¡å—çš„)èŠ‚ç‚¹å¿…é¡»é‡å†™  \n",
    "- ç›´æ¥è°ƒç”¨çš„éœ€è¦åœ¨inité‡Œåˆå§‹åŒ–PDNormç±»(æ›¿æ¢Norm),å¹¶åœ¨forwardé‡Œå¢åŠ promptåˆ°è¾“å…¥è¾“å‡º,training_stepä¹Ÿéœ€è¦ä¿®æ”¹,åŒ…æ‹¬ä»¥ä¸Šæ–¹æ³•(__init__,forward,training_step)è°ƒç”¨çš„æ–¹æ³•ã€‚  \n",
    "- é—´æ¥è°ƒç”¨çš„é™¤äº†ä¸éœ€è¦åˆå§‹åŒ–, å…¶ä½™ä¸€æ ·  \n",
    "- ä¸è°ƒç”¨çš„å°±ä¸ç”¨æ”¹äº†,å¯ä»¥ç”¨è„šæœ¬(Norm not in module.named_children)å¿«é€Ÿæ‰¾å‡º  \n",
    "\n",
    "æœ€å¤–å±‚ä¸¤ç§æ€è·¯:  \n",
    "- é‡å†™fLDM  \n",
    "- é‡å†™LatentDiffuion,å°†generative_model.model è½½å…¥ä¸º new_model,è€Œgenerative_modelçš„å®ä¾‹å˜é‡ä¼¼ä¹éƒ½æ˜¯ä¸ºäº†åˆå§‹åŒ–LatentDiffusionè½½å…¥çš„ä¸€äº›config,å› æ­¤ç›´æ¥load_state_dictæ²¡é—®é¢˜  \n",
    "    \n",
    "é‡å†™å,å¤–éƒ¨å…ˆè½½å…¥è€æ¨¡å‹?å†åˆå§‹åŒ–ä¸€ä¸ªæ–°çš„LatentDiffusionå¯¹è±¡ç›´æ¥load_state_dict  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "initå¹¶è½½å…¥ä¸€ä¸ªåŸå§‹æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "from dc_ldm.ldm_for_fmri import fLDM\n",
    "from config import Config_Generative_Model\n",
    "from dataset import create_Kamitani_dataset, create_BOLD5000_dataset\n",
    "\n",
    "\n",
    "\n",
    "class random_crop:\n",
    "    def __init__(self, size, p):\n",
    "        self.size = size\n",
    "        self.p = p\n",
    "    def __call__(self, img):\n",
    "        if torch.rand(1) < self.p:\n",
    "            return transforms.RandomCrop(size=(self.size, self.size))(img)\n",
    "        return img\n",
    "\n",
    "\n",
    "def normalize(img):\n",
    "    if img.shape[-1] == 3:\n",
    "        img = rearrange(img, 'h w c -> c h w')\n",
    "    img = torch.tensor(img)\n",
    "    img = img * 2.0 - 1.0 # to -1 ~ 1\n",
    "    return img\n",
    "\n",
    "def channel_last(img):\n",
    "        if img.shape[-1] == 3:\n",
    "            return img\n",
    "        return rearrange(img, 'c h w -> h w c')\n",
    "\n",
    "def fmri_transform(x, sparse_rate=0.2):\n",
    "    # x: 1, num_voxels\n",
    "    x_aug = copy.deepcopy(x)\n",
    "    idx = np.random.choice(x.shape[0], int(x.shape[0]*sparse_rate), replace=False)\n",
    "    x_aug[idx] = 0\n",
    "    return torch.FloatTensor(x_aug)\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "config = Config_Generative_Model()\n",
    "config.checkpoint_path = './results/generation/07-09-2023-01-50-29/checkpoint_best.pth'\n",
    "if config.checkpoint_path is not None:\n",
    "    model_meta = torch.load(config.checkpoint_path, map_location='cpu')\n",
    "    ckp = config.checkpoint_path\n",
    "    config = model_meta['config']\n",
    "    config.checkpoint_path = ckp  # æ›´æ–°configä¸­ckpä¸ºè¯»å–çš„ckp\n",
    "    print('Resuming from checkpoint: {}'.format(config.checkpoint_path))\n",
    "\n",
    "config.logger = None # FIXME:???\n",
    "pretrain_mbm_metafile = torch.load(config.pretrain_mbm_path, map_location='cpu')\n",
    "crop_pix = int(config.crop_ratio*config.img_size)\n",
    "\n",
    "img_transform_train = transforms.Compose([\n",
    "        normalize,\n",
    "        random_crop(config.img_size-crop_pix, p=0.5),\n",
    "        transforms.Resize((256, 256)), \n",
    "        channel_last\n",
    "    ])\n",
    "img_transform_test = transforms.Compose([\n",
    "        normalize, transforms.Resize((256, 256)), \n",
    "        channel_last\n",
    "    ])\n",
    "\n",
    "if config.dataset == 'GOD':\n",
    "    fmri_latents_dataset_train, fmri_latents_dataset_test = create_Kamitani_dataset(config.kam_path, config.roi, config.patch_size, \n",
    "            fmri_transform=fmri_transform, image_transform=[img_transform_train, img_transform_test], \n",
    "            subjects=config.kam_subs)\n",
    "    num_voxels = fmri_latents_dataset_train.num_voxels\n",
    "elif config.dataset == 'BOLD5000':\n",
    "    fmri_latents_dataset_train, fmri_latents_dataset_test = create_BOLD5000_dataset(config.bold5000_path, config.patch_size, \n",
    "            fmri_transform=fmri_transform, image_transform=[img_transform_train, img_transform_test], \n",
    "            subjects=config.bold5000_subs)\n",
    "    num_voxels = fmri_latents_dataset_train.num_voxels\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "generative_model = fLDM(pretrain_mbm_metafile, num_voxels,\n",
    "                device=device, pretrain_root=config.pretrain_gm_path, logger=config.logger, \n",
    "                ddim_steps=config.ddim_steps, global_pool=config.global_pool, use_time_cond=config.use_time_cond)\n",
    "\n",
    "\n",
    "def count_trainable_parameters(model):\n",
    "    for name, module in model.named_children():\n",
    "        trainable_params = sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
    "        non_trainable_params = sum(p.numel() for p in module.parameters() if not p.requires_grad)\n",
    "        print(f\"Module: {name}\")\n",
    "        print(f\"  Trainable parameters: {trainable_params/(1024*1024):.1f}M\")\n",
    "        print(f\"  Non-trainable parameters: {non_trainable_params/(1024*1024):.1f}M\")\n",
    "        print('-' * 40)\n",
    "\n",
    "# count_trainable_parameters(generative_model.model)\n",
    "stageC_model = copy.deepcopy(generative_model.model)\n",
    "if config.checkpoint_path is not None:  # ä»è‡ªå·±fintuneçš„checkpointè½½å…¥state\n",
    "        model_meta = torch.load(config.checkpoint_path, map_location='cpu')\n",
    "        stageC_model.load_state_dict(model_meta['model_state_dict'])\n",
    "        print('model resumed')\n",
    "count_trainable_parameters(stageC_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å†»ç»“first_stage_modelåï¼ŒæŸ¥çœ‹å‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stageC_model.freeze_first_stage()\n",
    "count_trainable_parameters(stageC_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ–°å»ºä¸€ä¸ªè‡ªå®šä¹‰çš„LDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç»Ÿè®¡ä¸åŒNormç±»çš„æ•°é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_norm(model):\n",
    "    norm_counts = {}\n",
    "    for name, module in model.named_modules():\n",
    "        class_name = module.__class__.__name__\n",
    "        # print(class_name)\n",
    "        if 'Norm' in class_name:\n",
    "            norm_counts[class_name] = norm_counts.get(class_name, 0) + 1\n",
    "            # print(module)   \n",
    "    print(norm_counts)\n",
    "\n",
    "def count_norm_i(model):\n",
    "    norm_counts = {}\n",
    "    for name, module in model.named_modules():\n",
    "        class_name = module.__class__.__name__\n",
    "        # print(class_name)\n",
    "        if 'Norm' in class_name:\n",
    "            norm_counts[class_name] = norm_counts.get(class_name, 0) + 1\n",
    "            # print(module)   \n",
    "    print(norm_counts)\n",
    "count_norm(stageC_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æŒ‰ç…§æ ‘çš„ç»“æ„æ‰“å°å„ä¸ªmoduleä¸­Normç±»çš„æ•°é‡ï¼Œä½œä¸ºé‡å†™å„moduleçš„å¯¹ç…§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, class_name, instance_name):\n",
    "        self.class_name = class_name\n",
    "        self.instance_name = instance_name\n",
    "        self.children = defaultdict(Node)\n",
    "        self.norm_count = 0\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        return self.children[key]\n",
    "\n",
    "    def display(self, indent=0):\n",
    "        prefix = '  ' * indent\n",
    "        if self.norm_count > 0:\n",
    "            print(f\"{prefix}({self.instance_name}){self.class_name}: {self.norm_count}\")\n",
    "        for child in self.children.values():\n",
    "            child.display(indent + 1)\n",
    "\n",
    "def build_tree(module, path=[]):\n",
    "    abs_instance_name = '.'.join(path)\n",
    "    instance_name = path[-1]\n",
    "    node = Node(module.__class__.__name__, instance_name)  # å°†\"ç±»å\"ä¼ å…¥åˆå§‹åŒ–1ä¸ªNode\n",
    "    # childrenä¸ºç©ºï¼Œnorm_count = 0\n",
    "    for child_instance_name, submodule in module.named_children():  # éå†å­æ¨¡å—è¿›è¡Œé€’å½’è°ƒç”¨\n",
    "        # abs_instance_name = '.'.join(path)\n",
    "        child_node = build_tree(submodule, path + [child_instance_name])  # å°†å­æ¨¡å—çš„name (instanc) å­˜åˆ°pathä¸­ï¼ŒæŒ‰ç…§ç±»åå»ºç«‹å­èŠ‚ç‚¹\n",
    "        # path è®°å½•äº†å­æ¨¡å—çš„å˜é‡å\n",
    "        # node.children[child_node.class_name] = child_node  \n",
    "        # # ä»¥å­èŠ‚ç‚¹ç±»åä¸ºkey(ä¼šå¯¼è‡´åŒåç±»åæ¥æ›¿ä»£çš„é—®é¢˜)ï¼Œå­èŠ‚ç‚¹Nodeå®ä¾‹ä¸ºvalueå­˜å…¥å®ä¾‹å˜é‡childrenå­—å…¸ä¸­\n",
    "        node.children[child_node.instance_name] = child_node \n",
    "        # æŒ‰ç…§instanceå»ºç«‹æ ‘åˆ™ä¸ä¼šé‡å¤ï¼Œdisplayæ—¶åœ¨æ‹¬å·ä¸­æ˜¾ç¤ºclass_nameå³å¯\n",
    "\n",
    "        if 'Norm' in submodule.__class__.__name__:\n",
    "            child_node.norm_count += 1\n",
    "\n",
    "        node.norm_count += child_node.norm_count\n",
    "\n",
    "    return node\n",
    "\n",
    "root = build_tree(generative_model.model,['ldm_model'])\n",
    "root.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "ä¿®æ”¹LatentDiffusionï¼ŒåŒ…æ‹¬ï¼š  \n",
    "**å±æ€§**ï¼š  \n",
    "- self.model\n",
    "- self.first_stage_model\n",
    "- self.cond_stage_model\n",
    "\n",
    "\n",
    "**æ–¹æ³•**ï¼š \n",
    "- training_step (DDPM,ç›´æ¥åœ¨LatentDiffusionä¸­é‡å†™å³å¯)\n",
    "    - shared_step (LatentDiffusion)\n",
    "        - get_input (LatentDiffusion)\n",
    "        - forward (LatentDiffusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdnorm_model import PDfLDM\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "config = OmegaConf.load('stageC_config.yaml')\n",
    "pd_model = PDfLDM(**config.model.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¿®æ”¹DiffusionWrapperåŠå…¶å­æ¨¡å—ï¼Œä¸€ä¸ªinstanceå…±åŒ…å«äº†109ä¸ªNorm (instance)  \n",
    "è‡ªä¸‹è€Œä¸Šé‡å†™  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_trainable_parameters(pd_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_norm(pd_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd_model.cond_stage_model.mae.pos_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,u = pd_model.load_state_dict(stageC_model.state_dict(),strict=False)\n",
    "print('missing keys:',m)\n",
    "print('-'*40)\n",
    "print('unexpected keys:',u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for missing_key in m:\n",
    "    if 'mlp_' not in missing_key:\n",
    "        print(missing_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_model2 = PDfLDM(**config.model.params)\n",
    "mm,uu = pd_model2.load_state_dict(model_meta['model_state_dict'],strict=False)\n",
    "print('missing keys:',mm)\n",
    "print('-'*40)\n",
    "print('unexpected keys:',uu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_trainable_parameters(pd_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for missing_key in mm:\n",
    "    if 'mlp_' not in missing_key:\n",
    "        print(missing_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdnorm_model import PDNorm\n",
    "def findout_norm(model):\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, PDNorm):\n",
    "            print(name, module)\n",
    "        else:\n",
    "            findout_norm(module)\n",
    "findout_norm(pd_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(pd_model.cond_stage_model.mae.blocks[22].norm2.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 2, 'c': 3}\n"
     ]
    }
   ],
   "source": [
    "a = ['a','b','c']\n",
    "b = [1,2,3]\n",
    "c = {k:v for k,v in zip(a,b)}\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val/a': 1, 'val/b': 2, 'val/c': 3}\n"
     ]
    }
   ],
   "source": [
    "d = {f'val/{k}':v for k,v in c.items()}\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‘€\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "checkpoint_path = '/data/xiaozhaoliu/stageC1/mind-vis/bjcgbjql/checkpoints/epoch=294-step=23600.ckpt'\n",
    "model_meta = torch.load(checkpoint_path, map_location='cpu')\n",
    "print('ğŸ‘€')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: 1.02 mins\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time_generating = time.time()\n",
    "time.sleep(61)\n",
    "end_time_generating = time.time()\n",
    "print(f\"Execution Time: {(end_time_generating - start_time_generating)/60:.2f} mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48]\n"
     ]
    }
   ],
   "source": [
    "grouped_fmri = [i for i in range(0, 50, 3)]\n",
    "print(grouped_fmri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9219)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure\n",
    "preds = torch.rand([3, 3, 256, 256])\n",
    "target = preds * 0.75\n",
    "ssim = StructuralSimilarityIndexMeasure(data_range=1.0)\n",
    "ssim(preds, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = preds[1:,:,:,:]\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7572, 0.0961, 0.7131],\n",
      "        [0.4517, 0.5330, 0.5896],\n",
      "        [0.5377, 0.6059, 0.1126]])\n",
      "tensor([[193,  24, 181],\n",
      "        [115, 135, 150],\n",
      "        [137, 154,  28]], dtype=torch.uint8)\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand([3, 3])\n",
    "print(x)\n",
    "y = (x*255).to(torch.uint8)\n",
    "print(y)\n",
    "z = y/255.\n",
    "print(z.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ˆ\n"
     ]
    }
   ],
   "source": [
    "print('\\U0001F4C8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "<class 'numpy.ndarray'>\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from einops import rearrange, repeat\n",
    "x = torch.rand([2, 3]).to(torch.device('cuda:0')).detach()\n",
    "print(x.device)\n",
    "y = rearrange(x, 'h w -> w h').cpu().numpy()\n",
    "print(type(y))\n",
    "print(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.uint8\n",
      "cuda:0\n",
      "torch.float32\n",
      "torch.uint8\n"
     ]
    }
   ],
   "source": [
    "grouped_images = torch.randint(0,255,(5,6,3,64,64)).to(torch.uint8).to(torch.device('cuda:0'))\n",
    "print(grouped_images.dtype)\n",
    "print(grouped_images.device)\n",
    "\n",
    "all_imgs = grouped_images/255.\n",
    "print(all_imgs.dtype)\n",
    "print(grouped_images.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "from PIL import Image\n",
    "images = rearrange(grouped_images, 'b n c h w -> (b n) c h w')\n",
    "grid = make_grid(images, nrow=grouped_images.shape[2])\n",
    "grid_rgb = rearrange(grid, 'c h w -> h w c')\n",
    "grid_PIL= Image.fromarray(grid_rgb.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recon_epoch_0001\n"
     ]
    }
   ],
   "source": [
    "ep=1\n",
    "print(f'recon_epoch_{ep:04}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-11-13-11-36-26\n",
      "231113-113626\n"
     ]
    }
   ],
   "source": [
    "from pytz import timezone\n",
    "from datetime import datetime\n",
    "print(datetime.utcnow().astimezone(timezone('Asia/Shanghai')).strftime(\"%y-%m-%d-%H-%M-%S\"))\n",
    "print(datetime.utcnow().astimezone(timezone('Asia/Shanghai')).strftime(\"%y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "23-11-13-11-37-24\n",
      "23-11-13-11-37-24/checkpoint\n"
     ]
    }
   ],
   "source": [
    "run_dir = datetime.utcnow().astimezone(timezone('Asia/Shanghai')).strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "print(type(run_dir))\n",
    "print(run_dir)\n",
    "ckpt_save_dir = run_dir + '/checkpoint'\n",
    "print(ckpt_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72c07df23ed64e6ca2c195774b3b8951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from rich.progress import track\n",
    "\n",
    "for i in track(range(20), description=\"Processing...\"):\n",
    "    time.sleep(0.1)  # Simulate work being done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bold][red]Done!\n"
     ]
    }
   ],
   "source": [
    "print(f'[bold][red]Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">           Todo List           </span>\n",
       "â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> S. No. </span>â”ƒ<span style=\"font-weight: bold\"> Task      </span>â”ƒ<span style=\"font-weight: bold\"> Status </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> 1      </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> Buy Milk  </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\">     âœ… </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> 2      </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> Buy Bread </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\">     âœ… </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> 3      </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\"> Buy Jam   </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\">     âŒ </span>â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m           Todo List           \u001b[0m\n",
       "â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mS. No.\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mTask     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mStatus\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m1     \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35mBuy Milk \u001b[0m\u001b[35m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32m    âœ…\u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m2     \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35mBuy Bread\u001b[0m\u001b[35m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32m    âœ…\u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m3     \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35mBuy Jam  \u001b[0m\u001b[35m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32m    âŒ\u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "\n",
    "table = Table(title=\"Todo List\")\n",
    "\n",
    "table.add_column(\"S. No.\", style=\"cyan\", no_wrap=True)\n",
    "table.add_column(\"Task\", style=\"magenta\")\n",
    "table.add_column(\"Status\", justify=\"right\", style=\"green\")\n",
    "\n",
    "table.add_row(\"1\", \"Buy Milk\", \"âœ…\")\n",
    "table.add_row(\"2\", \"Buy Bread\", \"âœ…\")\n",
    "table.add_row(\"3\", \"Buy Jam\", \"âŒ\")\n",
    "\n",
    "console = Console()\n",
    "console.print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The zipped result is : {('Nikhil', 1, 50), ('Manjeet', 4, 40), ('Shambhavi', 3, 60), ('Astha', 2, 70)}\n"
     ]
    }
   ],
   "source": [
    "# initializing lists \n",
    "name = [ \"Manjeet\", \"Nikhil\", \"Shambhavi\", \"Astha\" ] \n",
    "roll_no = [ 4, 1, 3, 2 ] \n",
    "marks = [ 40, 50, 60, 70 ] \n",
    "  \n",
    "# using zip() to map values \n",
    "mapped = zip(name, roll_no, marks) \n",
    "  \n",
    "# converting values to print as set \n",
    "mapped = set(mapped) \n",
    "  \n",
    "# printing resultant values  \n",
    "print (\"The zipped result is : \",end=\"\") \n",
    "print (mapped) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      " tensor([0, 1, 2, 3, 4])\n",
      "aa\n",
      ": tensor([[0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4]])\n",
      "b:\n",
      " tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4])\n",
      "c:\n",
      " tensor([10, 11, 12, 13, 14, 10, 11, 12, 13, 14, 10, 11, 12, 13, 14])\n",
      "d:\n",
      " tensor([[10, 11, 12, 13, 14],\n",
      "        [10, 11, 12, 13, 14],\n",
      "        [10, 11, 12, 13, 14]])\n"
     ]
    }
   ],
   "source": [
    "from einops import rearrange,repeat\n",
    "import torch\n",
    "\n",
    "a = torch.arange(0,5)\n",
    "print('a:\\n',a)\n",
    "aa = repeat(a, 'b -> n b', n=3)\n",
    "print('aa\\n:',aa)\n",
    "b = repeat(a, 'b -> (n b)', n=3)\n",
    "print('b:\\n',b)\n",
    "\n",
    "c = b+10\n",
    "print('c:\\n',c)\n",
    "d = rearrange(c,'(n b) -> n b',n=3,b=5)\n",
    "print('d:\\n',d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mind-vis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
