{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "npz = dict(np.load('./data/HCP/npz/100206/HCP_visual_voxel.npz'))\n",
    "# print()\n",
    "v1 = npz['V1']\n",
    "v2 = npz['V2']\n",
    "v3 = npz['V3']\n",
    "v4 = npz['V4']\n",
    "a = len(v1)\n",
    "b = np.array_split(v1,3,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在单一subject下，四个区域的fMRI数据尺寸为 (1200,1618),(1200,2220),(1200,684),(1200,661)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from config import Config_MBM_fMRI\n",
    "from dataset import hcp_dataset\n",
    "from stageA1_mbm_pretrain import fmri_transform\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "config = Config_MBM_fMRI()\n",
    "dataset_pretrain = hcp_dataset(path=os.path.join(config.root_path, 'data/HCP/npz'), roi=config.roi, patch_size=config.patch_size,\n",
    "                transform=fmri_transform, aug_times=config.aug_times, num_sub_limit=config.num_sub_limit, \n",
    "                include_kam=config.include_kam, include_hcp=config.include_hcp)\n",
    "sample_data = dataset_pretrain[6000]\n",
    "img = sample_data['image']\n",
    "image_array = np.array(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.get_device_properties(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import Config_MBM_fMRI\n",
    "\n",
    "config = Config_MBM_fMRI()\n",
    "\n",
    "config.num_voxels = 0\n",
    "print(config.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "config = OmegaConf.load('./pretrains/ldm/label2img/config.yaml')\n",
    "a = config['model'].get(\"params\", dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import copy\n",
    "from dc_ldm.ldm_for_fmri import fLDM\n",
    "from config import Config_Generative_Model\n",
    "from dataset import create_Kamitani_dataset, create_BOLD5000_dataset\n",
    "from einops import rearrange\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "class random_crop:\n",
    "    def __init__(self, size, p):\n",
    "        self.size = size\n",
    "        self.p = p\n",
    "    def __call__(self, img):\n",
    "        if torch.rand(1) < self.p:\n",
    "            return transforms.RandomCrop(size=(self.size, self.size))(img)\n",
    "        return img\n",
    "\n",
    "\n",
    "def normalize(img):\n",
    "    if img.shape[-1] == 3:\n",
    "        img = rearrange(img, 'h w c -> c h w')\n",
    "    img = torch.tensor(img)\n",
    "    img = img * 2.0 - 1.0 # to -1 ~ 1\n",
    "    return img\n",
    "\n",
    "def channel_last(img):\n",
    "        if img.shape[-1] == 3:\n",
    "            return img\n",
    "        return rearrange(img, 'c h w -> h w c')\n",
    "\n",
    "def fmri_transform(x, sparse_rate=0.2):\n",
    "    # x: 1, num_voxels\n",
    "    x_aug = copy.deepcopy(x)\n",
    "    idx = np.random.choice(x.shape[0], int(x.shape[0]*sparse_rate), replace=False)\n",
    "    x_aug[idx] = 0\n",
    "    return torch.FloatTensor(x_aug)\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "config = Config_Generative_Model()\n",
    "config.checkpoint_path = './results/generation/07-09-2023-01-50-29/checkpoint_best.pth'\n",
    "if config.checkpoint_path is not None:\n",
    "    model_meta = torch.load(config.checkpoint_path, map_location='cpu')\n",
    "    ckp = config.checkpoint_path\n",
    "    config = model_meta['config']\n",
    "    config.checkpoint_path = ckp  # 更新config中ckp为读取的ckp\n",
    "    print('Resuming from checkpoint: {}'.format(config.checkpoint_path))\n",
    "\n",
    "config.logger = None # FIXME:???\n",
    "pretrain_mbm_metafile = torch.load(config.pretrain_mbm_path, map_location='cpu')\n",
    "crop_pix = int(config.crop_ratio*config.img_size)\n",
    "\n",
    "img_transform_train = transforms.Compose([\n",
    "        normalize,\n",
    "        random_crop(config.img_size-crop_pix, p=0.5),\n",
    "        transforms.Resize((256, 256)), \n",
    "        channel_last\n",
    "    ])\n",
    "img_transform_test = transforms.Compose([\n",
    "        normalize, transforms.Resize((256, 256)), \n",
    "        channel_last\n",
    "    ])\n",
    "\n",
    "if config.dataset == 'GOD':\n",
    "    fmri_latents_dataset_train, fmri_latents_dataset_test = create_Kamitani_dataset(config.kam_path, config.roi, config.patch_size, \n",
    "            fmri_transform=fmri_transform, image_transform=[img_transform_train, img_transform_test], \n",
    "            subjects=config.kam_subs)\n",
    "    num_voxels = fmri_latents_dataset_train.num_voxels\n",
    "elif config.dataset == 'BOLD5000':\n",
    "    fmri_latents_dataset_train, fmri_latents_dataset_test = create_BOLD5000_dataset(config.bold5000_path, config.patch_size, \n",
    "            fmri_transform=fmri_transform, image_transform=[img_transform_train, img_transform_test], \n",
    "            subjects=config.bold5000_subs)\n",
    "    num_voxels = fmri_latents_dataset_train.num_voxels\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def print_trainable_params(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'norm' in name:\n",
    "            print(name, param.requires_grad)\n",
    "\n",
    "\n",
    "generative_model = fLDM(pretrain_mbm_metafile, num_voxels,\n",
    "                device=device, pretrain_root=config.pretrain_gm_path, logger=config.logger, \n",
    "                ddim_steps=config.ddim_steps, global_pool=config.global_pool, use_time_cond=config.use_time_cond)\n",
    "\n",
    "if config.checkpoint_path is not None:\n",
    "        model_meta = torch.load(config.checkpoint_path, map_location='cpu')\n",
    "        generative_model.model.load_state_dict(model_meta['model_state_dict'])\n",
    "        print('model resumed')\n",
    "\n",
    "\n",
    "# print_trainable_params(generative_model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generative_model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(5, 3, 256, 256)\n",
    "c = torch.randn(5,1,16)\n",
    "y = generative_model.model(x, c)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 打印命名中含有‘norm’字段的实例变量\n",
    "2. 遍历所有子模块后搜索“Norm”字段，确保模型中只有（nn.GroupNorm, nn.LayerNorm）\n",
    "3. 打印模型中所有Norm对象的变量名，发现变量名中的确有不含‘norm’的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import copy\n",
    "\n",
    "stageC_model = copy.deepcopy(generative_model.model)\n",
    "\n",
    "for name, param in stageC_model.named_parameters():\n",
    "    if 'norm' in name: \n",
    "        print(f\"Parameter name: {name}\")\n",
    "        print(f\"Parameter shape: {param.shape}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in stageC_model.named_modules():\n",
    "    if isinstance(module,(nn.GroupNorm, nn.LayerNorm)):\n",
    "        print(name)\n",
    "        print(module)\n",
    "        for para_name, param in module.named_parameters():\n",
    "            # print(para_name,'with shape:',param.shape)\n",
    "            print('++++++++++++++++++++++++++++',name) if not (para_name=='weight' or para_name=='bias') else None\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in stageC_model.named_modules():\n",
    "    if isinstance(module,(nn.GroupNorm, nn.LayerNorm)):\n",
    "        print('module name++++++',name)\n",
    "        # print(module.weight,module.bias)\n",
    "        stageC_model.add_module()\n",
    "        weight = module.weight\n",
    "        bias = module.bias\n",
    "        # for para_name, param in module.named_parameters():\n",
    "        #     print(para_name,'with shape:',param.shape)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.ln = nn.Linear(in_dim, out_dim)\n",
    "        # self.ln1 = nn.Linear(in_dim, hidden_dim)\n",
    "        # self.relu1 = nn.ReLU()\n",
    "        # self.ln2 = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.ln(x))\n",
    "        return x\n",
    "\n",
    "def replace_norm_layers_with_prompts(model):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.ModuleNorm):\n",
    "            num_features = module.num_features\n",
    "\n",
    "            # 提取 Norm 层的参数\n",
    "            weight = module.weight\n",
    "            bias = module.bias\n",
    "\n",
    "            # 创建 MLP 模型\n",
    "            mlp = MLP(num_features, num_features)\n",
    "\n",
    "            # 将 MLP 模型的参数设置为外部训练得到的参数\n",
    "            mlp.linear.weight.data.copy_(weight.view(num_features, 1))\n",
    "            mlp.linear.bias.data.copy_(bias.view(num_features, 1))\n",
    "\n",
    "            # 使用 MLP 输出的参数替换原始的 Norm 层参数\n",
    "            module.weight = nn.Parameter(mlp.linear.weight)\n",
    "            module.bias = nn.Parameter(mlp.linear.bias)\n",
    "\n",
    "# 替换\n",
    "stageC_model = generative_model.model\n",
    "\n",
    "# 替换 Norm 层的可训练参数为 MLP 训练得到的参数\n",
    "replace_norm_layers_with_prompts(stageC_model)\n",
    "\n",
    "# 在外部训练 MLP 模型...\n",
    "# 将 MLP 输出的参数赋值给替换后的 Norm 层参数...\n",
    "\n",
    "# 模型训练过程..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    total_params = 0\n",
    "    frozen_params = 0\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        total_params += param.numel()\n",
    "        if not param.requires_grad:\n",
    "            print(name)\n",
    "            frozen_params += param.numel()\n",
    "\n",
    "    percentage_frozen = (frozen_params / total_params) * 100\n",
    "    return total_params, percentage_frozen\n",
    "\n",
    "total_params, frozen_percentage = count_parameters(generative_model.model)\n",
    "print(\"Total parameters: {:.2,}M\".format(total_params/(1024*1024)))\n",
    "print(\"Frozen parameters percentage: {:.2f}%\".format(frozen_percentage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在所有的可训练参数中，将norm参数"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mind-vis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
